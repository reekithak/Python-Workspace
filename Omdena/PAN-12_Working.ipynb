{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work on PAN-12\n",
    "Akhil Sanker (reekithak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T04:10:20.161740Z",
     "start_time": "2020-09-04T04:10:13.026859Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i) Identifying the Dataset Points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T04:10:28.282296Z",
     "start_time": "2020-09-04T04:10:20.171713Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    Train_pos = pd.read_csv(r\"D:\\working repos\\Python-Workspace\\Omdena\\Train_pos.csv\")\n",
    "    Train_neg = pd.read_csv(r\"D:\\working repos\\Python-Workspace\\Omdena\\Train_Neg.csv\")\n",
    "    Test_pos = pd.read_csv(r\"D:\\working repos\\Python-Workspace\\Omdena\\Test_pos.csv\")\n",
    "    Test_neg = pd.read_csv(r\"D:\\working repos\\Python-Workspace\\Omdena\\Test_Neg.csv\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "try:\n",
    "    Train_pos = Train_pos.drop(\"Unnamed: 0\",axis=1)\n",
    "    Train_neg = Train_neg.drop(\"Unnamed: 0\",axis=1)\n",
    "    Test_pos = Test_pos.drop(\"Unnamed: 0\",axis=1)\n",
    "    Test_neg = Test_neg.drop(\"Unnamed: 0\",axis=1)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-30T21:57:34.099929Z",
     "start_time": "2020-08-30T21:57:34.072002Z"
    }
   },
   "source": [
    "**Random Mixing up of Id's to check relation ( if any )**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T04:10:28.420633Z",
     "start_time": "2020-09-04T04:10:28.292270Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3994, 193943)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#positive\n",
    "pos1_list = Train_pos['ID'].to_list()\n",
    "pos2_list = Test_pos['ID'].to_list()\n",
    "pos_list = pos1_list + pos2_list\n",
    "#negative\n",
    "neg1_list = Train_neg['ID'].to_list()\n",
    "neg2_list = Test_neg['ID'].to_list()\n",
    "neg_list = neg1_list + neg2_list\n",
    "len(pos_list) , len(neg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T04:10:28.623727Z",
     "start_time": "2020-09-04T04:10:28.432603Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "from fractions import Fraction\n",
    "print(Fraction(len(neg_list)//len(pos_list)).limit_denominator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T04:10:28.873378Z",
     "start_time": "2020-09-04T04:10:28.632820Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(set(), 3994, 193943)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_ids = set(neg_list).intersection(set(pos_list))\n",
    "common_ids ,len(set(pos_list)),len(set(neg_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : \n",
    "1) Its clearly visible that the dataset has the issue of Class imbalance , can be treated on a later stage using Oversampling\n",
    "2) Null Set Returned , shows no overlapping of people also no chat / person is repeated ! (value notifying! )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii) Working code** - Without oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T08:18:53.388660Z",
     "start_time": "2020-09-02T08:18:53.187614Z"
    }
   },
   "source": [
    "Merging the data - 0 non Abusive , 1 Abusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T04:10:29.527628Z",
     "start_time": "2020-09-04T04:10:28.883352Z"
    }
   },
   "outputs": [],
   "source": [
    "pos_data = pd.concat([Train_pos,Test_pos],axis=0) \n",
    "neg_data = pd.concat([Train_neg,Test_neg],axis=0)\n",
    "pos_data['class'] = [0 for x in range(pos_data.shape[0])]\n",
    "neg_data['class'] = [1 for x in range(neg_data.shape[0])]\n",
    "Data = pd.concat([pos_data,neg_data]) #Merged Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T04:10:29.605138Z",
     "start_time": "2020-09-04T04:10:29.535606Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                 ID  \\\n",
       " 0  0014c1b4278df4bf8ea8a20b7abdb13c   \n",
       " 1  0027f42308aad202fcb7224597a7ac1a   \n",
       " 2  0063692c957229db0816e0f240d7fa0d   \n",
       " 3  00a88e94773667ea0146e223d8d22f44   \n",
       " 4  00b06ff8fb883556067a7f53c06455fe   \n",
       " \n",
       "                                   Comments / Message  class  \n",
       " 0  hi.hi.how r ya?.where u been.im cool.was out w...      0  \n",
       " 1  hey baby.hey.i took a shower.kool.just seeing ...      0  \n",
       " 2  hello.hey.a little late but I am here.yea.so w...      0  \n",
       " 3  u still here ?.im sorry but i dont think I can...      0  \n",
       " 4  so--you on??.I know you're around cause I just...      0  ,\n",
       "                                       ID  \\\n",
       " 135752  fffc29bad1debf0fc42c0fe4b921a192   \n",
       " 135753  fffd9ce69d28d71b407c6ae24c3973e6   \n",
       " 135754  fffe4d1b08952afb8627a9b594f913c7   \n",
       " 135755  ffff2d0e314610b1df596482d806ada9   \n",
       " 135756  ffff74f40b58182a2521235b9db901d4   \n",
       " \n",
       "                                        Comments / Message  class  \n",
       " 135752                   hi.hi.Rødgrød med fløde?.asl?.        1  \n",
       " 135753  hey, why can't we edit the topic?.icefox: we'r...      1  \n",
       " 135754  do you want to chat?.here not on msn.i don&amp...      1  \n",
       " 135755  Haiiiiiiiii..Can you help me?.):.sure...with w...      1  \n",
       " 135756  hey.hi.lookingfor girl?.r u girl?.yes.u?.what ...      1  )"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.head(5) , Data.tail(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T04:10:29.824633Z",
     "start_time": "2020-09-04T04:10:29.628076Z"
    }
   },
   "outputs": [],
   "source": [
    "#Creating lists\n",
    "X_train = Data['Comments / Message'].to_list()\n",
    "Y_train = Data['class'].to_list()\n",
    "from cleantext import clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T04:21:00.256704Z",
     "start_time": "2020-09-04T04:21:00.245734Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cleaning the X_train data\n",
    "#X_train = [clean_text(x) for x in X_train]\n",
    "len(X_train) == len(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bag-of-Words**: Feature Engineering & Feature Selection & Machine Learning with scikit-learn, Testing & Evaluation,Explainability with lime.\n",
    "\n",
    "**Word Embedding**: Fitting a Word2Vec with gensim, Feature Engineering & Deep Learning with tensorflow/keras, Testing & Evaluation, Explainability with the Attention mechanism.\n",
    "\n",
    "**Language Models**: Feature Engineering with transformers, Transfer Learning from pre-trained BERT with transformers and tensorflow/keras, Testing & Evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T04:21:01.306438Z",
     "start_time": "2020-09-04T04:21:01.297462Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'work_data = pd.DataFrame()\\nwork_data[\\'Text\\'] = X_train ; work_data[\\'class\\'] = Y_train\\nwork_data.to_csv(\"cleaned_data.csv\")'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''work_data = pd.DataFrame()\n",
    "work_data['Text'] = X_train ; work_data['class'] = Y_train\n",
    "work_data.to_csv(\"cleaned_data.csv\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T05:05:31.054513Z",
     "start_time": "2020-09-04T05:05:30.019073Z"
    }
   },
   "outputs": [],
   "source": [
    "import json \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "#bag of words\n",
    "from sklearn import feature_extraction , model_selection , naive_bayes , pipeline , manifold , preprocessing \n",
    "\n",
    "#explainer\n",
    "from lime import lime_text \n",
    "\n",
    "#Word Embedding\n",
    "import gensim \n",
    "import gensim.downloader as gensim_api\n",
    "\n",
    "#deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models , layers , preprocessing as kprocessing\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "#bert model\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
